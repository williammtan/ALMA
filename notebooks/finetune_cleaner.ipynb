{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4df9c0bf-6f9d-4e1c-96f2-0ac0d5283a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.35.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Collecting together\n",
      "  Downloading together-1.2.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/conda/lib/python3.10/site-packages (from together) (8.1.7)\n",
      "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from together)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from together)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting typer<0.13,>=0.9 (from together)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Collecting shellingham>=1.3.0 (from typer<0.13,>=0.9->together)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<0.13,>=0.9->together)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<0.13,>=0.9->together)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<0.13,>=0.9->together) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.13,>=0.9->together)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading together-1.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: tabulate, shellingham, pillow, mdurl, eval-type-backport, markdown-it-py, rich, typer, together\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 10.0.1\n",
      "    Uninstalling Pillow-10.0.1:\n",
      "      Successfully uninstalled Pillow-10.0.1\n",
      "Successfully installed eval-type-backport-0.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 pillow-10.3.0 rich-13.7.1 shellingham-1.5.4 tabulate-0.9.0 together-1.2.1 typer-0.12.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets openai python-dotenv together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c2143ea-702b-4872-b0bf-af9d356d5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, combinations\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "466e66d7-e3db-4ac3-b7d6-ffa718ab4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTIL FUNCTIONS\n",
    "\n",
    "LLAMA3_PROMPT = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{system_prompt}\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{model_answer}<|eot_id|>\"\"\"\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "    # Convert indexes to a set for O(1) lookups\n",
    "    indexes_set = set(indexes)\n",
    "    # Use list comprehension to filter out unwanted indexes\n",
    "    return [item for i, item in enumerate(lst) if i not in indexes_set]\n",
    "\n",
    "def get_lang_directions(languages, base_languages, order_matters=True, skip_base_pairs=False):\n",
    "    \"\"\"Helper function to generate the language directions.\"\"\"\n",
    "\n",
    "    directions = []\n",
    "    \n",
    "    for base in base_languages:\n",
    "        if skip_base_pairs:\n",
    "            other_languages = [lang for lang in languages if lang not in base_languages]\n",
    "        else:\n",
    "            other_languages = [lang for lang in languages if lang != base]\n",
    "\n",
    "        for lang in other_languages:\n",
    "\n",
    "            if order_matters:\n",
    "                directions.append((base, lang))\n",
    "                directions.append((lang, base))\n",
    "            else:\n",
    "                pair = tuple(sorted([base, lang]))\n",
    "                if pair not in directions:\n",
    "                    directions.append(pair)\n",
    "    \n",
    "    return directions\n",
    "\n",
    "def create_batch_requests(df, prompt, model, output_filename):\n",
    "    \"\"\"Creates and dumps the batch requests to the output_filename .jsonl file\"\"\"\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        for i,row in df.iterrows():\n",
    "            source_lang_name = LANGUAGE_NAMES[row[\"source_lang\"]]\n",
    "            target_lang_name = LANGUAGE_NAMES[row[\"target_lang\"]]\n",
    "            f.write(json.dumps({\n",
    "                  \"custom_id\": f\"batch-clean-{i}\",\n",
    "                  \"method\": \"POST\",\n",
    "                  \"url\": \"/v1/chat/completions\",\n",
    "                  \"body\": {\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                          \"role\": \"system\",\n",
    "                          \"content\": prompt\n",
    "                        },\n",
    "                        {\n",
    "                          \"role\": \"user\",\n",
    "                          \"content\": f'{source_lang_name}: {row[\"source_sentence\"]}\\n{target_lang_name}: {row[\"target_sentence\"]}\\nCleaned:\\n'\n",
    "                        }\n",
    "                    ],\n",
    "                    \"max_tokens\": 256\n",
    "                  }\n",
    "                })+\"\\n\")\n",
    "\n",
    "def run_batch(filename):\n",
    "    batch_input_file = client.files.create(\n",
    "      file=open(filename, \"rb\"),\n",
    "      purpose=\"batch\"\n",
    "    )\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    return client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "          \"description\": \"batch clean job\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "def get_batch_results(batch_id):\n",
    "    file_id = client.batches.retrieve(batch_id).output_file_id\n",
    "    results_str = client.files.content(file_id).content.decode(\"utf-8\")\n",
    "\n",
    "    response_df = pd.DataFrame(columns=[\"source_sentence_cleaned\", \"target_sentence_cleaned\"])\n",
    "    for line in results_str.split('\\n')[:-1]:\n",
    "        o = json.loads(line)\n",
    "        i = int(o[\"custom_id\"].replace('batch-clean-', ''))\n",
    "\n",
    "        response_str = o[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "        re_pattern = r'(\\w+):\\s*([^\\n]+)\\n(\\w+):\\s*(.+)'\n",
    "        match = re.search(pattern, response_str)\n",
    "        if match is None or len(match.groups()) != 4:\n",
    "            print(f\"WARNING: Unparsable response: \\\"{response_str}\\\", response will be saved as a empty string\")\n",
    "            source_sentence = \"\"\n",
    "            target_sentence = \"\"\n",
    "        else:\n",
    "            source_sentence = match.group(2)\n",
    "            target_sentence = match.group(4)\n",
    "        response_df.loc[i] = [source_sentence, target_sentence]\n",
    "    return response_df\n",
    "\n",
    "def example_to_llama3(example, system_prompt):\n",
    "    src_lang = LANGUAGE_NAMES[example[\"source_lang\"]]\n",
    "    tgt_lang = LANGUAGE_NAMES[example[\"target_lang\"]]\n",
    "    user_message = f'{src_lang}: {example[\"source_sentence\"]}\\n{tgt_lang}:{example[\"target_sentence\"]}'\n",
    "    model_answer = f'{src_lang}: {example[\"source_sentence_cleaned\"]}\\n{tgt_lang}:{example[\"target_sentence_cleaned\"]}'\n",
    "\n",
    "    return LLAMA3_PROMPT.format(\n",
    "        system_prompt=system_prompt,\n",
    "        user_message=user_message,\n",
    "        model_answer=model_answer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca01e9b-525f-4bc2-adde-91cd66e268cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/load.py:2562: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c6d5f924d4481e846e8a9b6cb65c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/9.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9efc7b824f8454783683c0ee4bfd009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/5.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19574d7894e647a48ff53fe25ccd0c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/38.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bc695e1f6f4b26a2588892bdde17da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/81.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f15e3f15d04432a709988ca1b742ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/57.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ec814c47654cbeb4241ffeee83bb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/324936 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e0a8f4bc294108ba0e72cbab0f3df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4a01ff05be4bcdafb73b6207a8e034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2443442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8c9cf0b0e44084aad98ff526d1eae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/141M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24af8b6a1a6a444aa714023f8775c379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/766894 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f526da4cbf45bebae67b7d4cc886f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/213M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f19cb5a553497bb843ceed342af6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1240098 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c4fb0d688949fa99e9d39ea60a67be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188e5b75b6254c639a82e6ddb6dba4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/301972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6558e8dcd84a71b6c1373ac5b175c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac1d9292e744c2d9072fb45d466eb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11779642 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e3e41b836c4dc88e7e5f471bf8cada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b1ef983e134b51894b16f5cd88d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16948924 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a217faaa2d4a6dbb21a1305052745d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73276081d50a4c658be19f63357b0f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/152M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e364643795649d49c9e18966829eb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/732976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea295baff2bb457591e3fcdc27d733a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/291M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf22ce06f194f7bad81b68c43379920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1454976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e68c798d58c49c2af4061af852223e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/317M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c926fbc2d84a6eae1f924d98e73f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1455384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Removed bug_Latn-ind_Latn direction because it cannot be found in the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ba0dec0dac4e9a831fcaacfa0914d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da4f922aecf41288e61beeaa7d13fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1466998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2bb6b25fb4daa9c188fe5e77fe0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/637M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825160c8d82d4b21b41283d420f07cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3029624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dba477765b424f836b1a4a6bb76e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38930260447149918f979ed0ae83f4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1929462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD DATASETS\n",
    "\n",
    "LANGUAGES = [\n",
    "    'ban_Latn',\n",
    "    'ace_Latn',\n",
    "    'bjn_Latn',\n",
    "    'bug_Latn',\n",
    "    'min_Latn',\n",
    "    'sun_Latn',\n",
    "    'jav_Latn',\n",
    "    'ind_Latn',\n",
    "    'eng_Latn'\n",
    "]\n",
    "BASE_LANGUAGES = [\n",
    "    \"eng_Latn\",\n",
    "    \"ind_Latn\"\n",
    "]\n",
    "LANGUAGE_NAMES = {\n",
    "    'ban_Latn': 'Balinese',\n",
    "    'ace_Latn': 'Acehnese',\n",
    "    'bjn_Latn': 'Banjar',\n",
    "    'bug_Latn': 'Buginese',\n",
    "    'min_Latn': 'Minangkabau',\n",
    "    'sun_Latn': 'Sundanese',\n",
    "    'jav_Latn': 'Javanese',\n",
    "    'ind_Latn': 'Indonesian',\n",
    "    'eng_Latn': 'English'\n",
    "}\n",
    "DIRECTIONS = get_lang_directions(LANGUAGES, BASE_LANGUAGES, order_matters=False, skip_base_pairs=True)\n",
    "datasets = []\n",
    "remove_indices = []\n",
    "\n",
    "for i, (lang1, lang2) in enumerate(DIRECTIONS):\n",
    "    try:\n",
    "        dataset = load_dataset(\"allenai/nllb\", f\"{lang1}-{lang2}\", ignore_verifications=True, trust_remote_code=True)[\"train\"]\n",
    "    except ValueError:\n",
    "        try:\n",
    "            dataset = load_dataset(\"allenai/nllb\", f\"{lang2}-{lang1}\", ignore_verifications=True, trust_remote_code=True)[\"train\"]\n",
    "        except ValueError:\n",
    "            remove_indices.append(i)\n",
    "            print(f\"WARNING: Removed {lang1}-{lang2} direction because it cannot be found in the dataset\")\n",
    "            continue\n",
    "    datasets.append(dataset)\n",
    "\n",
    "DIRECTIONS = remove_indexes(DIRECTIONS, remove_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393141c7-e42c-4104-b91d-c73fadd5c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data/cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22714654-8cba-4cf2-b5bc-51b34cd8c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERING\n",
    "\n",
    "NUM_SAMPLES_PER_DIRECTION = 100\n",
    "LID_THRESHOLD = 0.9\n",
    "LASER_SCORE_THRESHOLD = 1.07\n",
    "\n",
    "DF_STORE = \"../data/cleaner/examples_df.pkl\"\n",
    "\n",
    "if 'df' in globals():\n",
    "    df = pd.read_pickle(DF_STORE)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"source_lang\", \"target_lang\", \"source_sentence\", \"target_sentence\"])\n",
    "    \n",
    "    i = 0\n",
    "    for di, d in enumerate(datasets):\n",
    "        direction = DIRECTIONS[di]\n",
    "        n = 0\n",
    "        for ex in d:\n",
    "            if n > NUM_SAMPLES_PER_DIRECTION:\n",
    "                break\n",
    "            \n",
    "            if ex[\"laser_score\"] >= LASER_SCORE_THRESHOLD and ex[\"source_sentence_lid\"] >= LID_THRESHOLD and ex[\"target_sentence_lid\"] >= LID_THRESHOLD:\n",
    "                df.loc[i] = [direction[0], direction[1], ex[\"translation\"][direction[0]], ex[\"translation\"][direction[1]]]\n",
    "                n+=1\n",
    "                i+=1\n",
    "    \n",
    "    df.to_pickle(DF_STORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c89124-4e27-4d34-b631-a85deff56a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EXAMPLES FOR FINETUNED GPT\n",
    "\n",
    "FT_GPT_EXAMPLE_FILEPATH = \"../data/cleaner/ft-examples.jsonl\"\n",
    "FT_PROMPT = \"Clean the data by identifying and fixing problems in parallel sentences. The problems include misalignment, repetition, incomplete translations, and inconsistent formatting.\"\n",
    "\n",
    "\n",
    "create_batch_requests(\n",
    "    df, \n",
    "    prompt=FT_GPT_EXAMPLE_FILEPATH, \n",
    "    model=\"ft:gpt-3.5-turbo-0125:personal::9T5FmQKr\", \n",
    "    output_filename=FT_GPT_EXAMPLE_FILEPATH\n",
    ")\n",
    "ft_batch = run_batch(FT_GPT_EXAMPLE_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8cf667bf-53da-4eb6-a90f-8cce73341b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Unparsable response: \"Balinese: sajeroning cakepan suci sané marupa lontar, sané mapurwa.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Balinese: Santukan Ida Sang Hyang Roh Suci miwah tiang sareng sami sampun pada adung, tan jaga mabaatin semeton antuk tetegenan sane lianan, sajawining paindikan sane perlu puniki:\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Kok santano urang-urang tu layi mangatawui, tantu indak ka inyo salibkan doh Tuhan nan mulie tu.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: mana ada seh surga yang sama kayak Dunia? kalo surga sama kayak dunia, ya kl gitu ngapain ke surga??\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Tapi itu alun lai tando baraso nagari ka kiamaik. Sudah tu Isa Almasih manaruihkan pulo pambicaroan-Nyo, Baliau mangatokan, Banso nan ciyek ka baparang malawan banso nan lain, nagara nan ciyek ka manyarang nagara nan lain.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Inya bapandapat bahwa kakayaan sabuting negara bagantung wan akumulasi amas wan peraknya. English: It held that a nation's wealth depended on its accumulation of gold and silver.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Aha winihihowono ngini ganga o Musa, ünanga ngini\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Jar nabi ibrahim: kada malihat lah bubuhan ikam?\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: kadada ni'mat nang paling bagus kacuali malihat muha Rasulullah saw.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: sial banget ya jadi bumi udah ditumpangin masih aja dirusak dasar manusia.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Itu sababnyo mangko angkau musti mamparingekkan urang-urang tu sacaro jaleh; supayo inyo tatap bapacik ka pangajaran nan bana, sarato indak lai bapacik kabake kaba bagalau urang Yahudi, atau ka sagalo paratuaran nan dibuwek, dek urang-urang nan manulak pangajaran nan bana tu.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Iya jadi tuh kayak lagi jalan jalan di lembah gunungnya gitu. English: They are like a journey into the mountains.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Tapi bagaimanakah sifat dari kenikmatan-kenikmatan dalam surga, dan apa bedanya dengan kenikmatan-kenikmatan yang ada di dunia ini?\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Sabalun aja bapantang mati, Namun di dalam kabanaran.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: Commentary by Sayyid Qutb In the name of God, the Lord of Grace, the Ever Merciful Say: 'My Lord gives in abundance, or gives in scant measure, to whomever He wills; but most people do not understand.' Sundanese: Hayu urang lenyepan dawuhan-Na dina al-Qur'an surat Saba', ayat 36, anu unina: 'Pék caritakeun: Satemenna Pangéran kuring nu ngajembaran rijki keur sing saha baé anu dipikahoyong-Na jeung ngaheureutan (pikeun sing saha baé anu dipikahoyongna), tapi kalolobaan manusa henteu apal.'\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: This is from the Grace of Allâh to us and to mankind, but most men thank not.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: It is only the Shaitan that causes you to fear from his friends, but do not fear them, and fear Me if you are believers.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: This is from the Grace of Allah to us and to mankind, but most men thank not.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: You are not aware of the other side of My scheme but Surely, I know that which you do not know.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"English: I had no knowledge of the high chiefs, as they discussed among themselves.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Balinese: Tresna asih Idane punika prasida sampurna sajeroning iraga, tetujonipun mangdane iraga prasida molih kawanenan ring Rahina Pangadilane; iraga pacang dados purun, santukan urip iragane ring jagate puniki pateh sakadi urip Ida Sang Kristus.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: Udah mw lawan Adachi nih di P4 !!\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: speknya tuh 2x 45w.di ampguts ada speknya.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Setiap orang mempunyai hak untuk taraf hidup yang menjamin kesehatan dan kesejahteraan untuk dirinya dan keluarganya, termasuk pangan, pakaian, perumahan dan perawatan kesehatannya serta pelayanan sosial yang diperlukan, dan berhak atas jaminan dalam hal pengangguran, sakit, cacat, janda, usia tua atau kurangnya mata pencaharian lain di luar kekuasaannya.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: sakit beuth jadi ming, nyesel aja kyu nanti kalo ditinggal ming.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: aq hampir gila mikirin remun , tapi dikasih tuh , jadi agak lega.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: bahan tile jala, kerut karet dibagian pinggang, kerut karet dibagian lengan dan belakang, aplikasi manik-manik dibagian depan, motif renda dibagian depan.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Banjar: mau rubah pcd atau pakai adaptor dulu gak om? kalo iya beapa tebel? baru di itung lagi.\", response will be saved as a empty string\n"
     ]
    }
   ],
   "source": [
    "ft_results = get_batch_results(ft_batch.id)\n",
    "ft_df = df.join(ft_results)\n",
    "ft_df = ft_df[(ft_df[\"source_sentence_cleaned\"] != \"\")&(ft_df[\"target_sentence_cleaned\"] != \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f23ce8dc-a3b5-4723-9b0e-d42a861697ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA3_SYSTEM_PROMPT = \"Clean the data by identifying and fixing problems in parallel sentences. The problems include misalignment, repetition, incomplete translations, and inconsistent formatting. Provide the cleaned output without any repetition.\"\n",
    "\n",
    "with open(\"../data/cleaner/together_cleaner_examples.jsonl\", \"w\") as f:\n",
    "    for _, row in ft_df.iterrows():\n",
    "        f.write(json.dumps({\n",
    "            \"text\": example_to_llama3(row, LLAMA3_SYSTEM_PROMPT)\n",
    "        }) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d929668-a9db-49c4-bede-b63384aa7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE EXAMPLES FOR FEW SHOT GPT 4o\n",
    "\n",
    "GPT4_EXAMPLE_FILEPATH = \"../data/cleaner/gpt4-examples.jsonl\"\n",
    "GPT4_PROMPT = \"\"\"\n",
    "Clean the data by identifying and fixing problems in parallel sentences. The problems include misalignment, repetition, incomplete translations, and inconsistent formatting. Provide the cleaned output without any repetition.\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. \n",
    "Balinese: Anake akeh punika tumuli pada mabebaosan, sapuniki: 'Singke Anake ene pianak Yusupe?'\n",
    "English: They said among themselves, 'Could this, at last, be the Son of Joseph?'\n",
    "Cleaned:\n",
    "Balinese: Anake akeh punika tumuli pada mabebaosan, sapuniki: 'Singke Anake ene pianak Yusupe?'\n",
    "English: They said among themselves, 'Is this not Joseph's son?'\n",
    "\n",
    "2.\n",
    "Balinese: 15 Paurukan Ida Sang Panembahan sane tuturang tiang ring parasemeton, kadi asapuniki: iraga sane kantun urip ring rahina pangrauh Ida Sang Panembahan, tan pacang ngriinin anake sane sampun padem.\n",
    "English: 15) According to the Lord's word, we tell you that we who are still alive, who are left until the coming of the Lord, will certainly not precede those who have fallen asleep.\n",
    "Cleaned:\n",
    "Balinese: 15 Paurukan Ida Sang Panembahan sane tuturang tiang ring parasemeton, kadi asapuniki: iraga sane kantun urip ring rahina pangrauh Ida Sang Panembahan, tan pacang ngriinin anake sane sampun padem.\n",
    "English: 15 According to the Lord's word, we tell you that we who are still alive, who are left until the coming of the Lord, will certainly not precede those who have fallen asleep.\n",
    "\n",
    "3.\n",
    "Balinese: 4.Sane ngiring Ida wantah parautusan Idane kewanten.'\n",
    "English: Only the APOSTLES were there.\n",
    "Cleaned:\n",
    "Balinese: Sane ngiring Ida wantah parautusan Idane kewanten.\n",
    "English: Only the apostles were there.\n",
    "\n",
    "4.\n",
    "Balinese: Bali: Sakadi sane sinurat ring Cakepan Sucine: 'Tusing ada anak ane patut,'\n",
    "English: As it is written: 'There is none righteous, no, not one (Rom.'\n",
    "Cleaned:\n",
    "Balinese: Sakadi sane sinurat ring Cakepan Sucine: 'Tusing ada anak ane patut,'\n",
    "English: As it is written: 'There is none righteous, no, not one.'\n",
    "\n",
    "5.\n",
    "Balinese: 31Uning semeton napi ke punika rahina soma ribek?\n",
    "English: 31 And what do you know what the Day of Decision is?\n",
    "Cleaned:\n",
    "Balinese: 31 Uning semeton napi ke punika rahina soma ribek?\n",
    "English: 31 And what do you know what the Day of Decision is?\n",
    "\"\"\"\n",
    "\n",
    "create_batch_requests(\n",
    "    df, \n",
    "    prompt=GPT4_PROMPT, \n",
    "    model=\"gpt-4o\", \n",
    "    output_filename=GPT4_EXAMPLE_FILEPATH\n",
    ")\n",
    "gpt4_batch = run_batch(GPT4_EXAMPLE_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4bfeeb75-45f9-48c0-9530-5dd59e2d8a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Unparsable response: \"This appears to be a case of severe misalignment; the sentences do not match contextually. Consequently, it is impossible to clean the data effectively without modifying the context. No feasible cleaned output can be provided from the given entries due to this misalignment.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Balinese: Napi malih Visi nyijur Bali Anyar sane nedeng kemargiang anggen nangiang antuk ngenterang saking dasar lan jangkep pembangunan ring Bali, utamane ring baga adat lan budaya sane katedunan ring pengangken lan mikukuhin Desa Adat, sekadi kasurat ring Perda Provinsi Bali Nomor 4 Warsa 2019 indik Desa Adat di Bali, raris dahat sairing antuk prinsip Tri Sakti sane dumun kaodar olih Ir. Soekarno.\n",
      "\n",
      "Indonesian: Apalagi visi menuju Bali Era Baru yang sedang proses untuk diwujudkannya dengan menata secara fundamental dan komprehensif pembangunan di Bali, utamanya di bidang adat dan budaya yang ditransformasikan ke dalam pengakuan dan penguatan desa adat sangat sejalan dengan prinsip Tri Sakti yang pernah disampaikan oleh Ir. Soekarno.\", response will be saved as a empty string\n",
      "WARNING: Unparsable response: \"Indonesian: karakter kartun Looney Tunes, yaitu Taz\n",
      "Minangkabau:\", response will be saved as a empty string\n"
     ]
    }
   ],
   "source": [
    "gpt4_results = get_batch_results(gpt4_batch.id)\n",
    "gpt4_df = df.join(gpt4_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
